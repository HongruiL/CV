{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1d10f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集划分: 训练=2640, 验证=661\n",
      "加载 train 数据集: 2640 个样本\n",
      "加载 train 数据集: 661 个样本\n",
      "\n",
      "Batch信息:\n",
      "  图像shape: torch.Size([16, 3, 224, 224])\n",
      "  卡路里shape: torch.Size([16])\n",
      "  卡路里值: tensor([113.9100, 321.5300,   0.0000, 504.8209, 298.1194])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class Nutrition5kDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Nutrition5K 数据集加载器\n",
    "    \n",
    "    Args:\n",
    "        csv_file: CSV文件路径，包含ID和Value列\n",
    "        data_root: 数据根目录\n",
    "        split: 'train' 或 'test'\n",
    "        transform: 图像变换\n",
    "        use_depth: 是否使用深度图（默认False，baseline只用RGB）\n",
    "    \"\"\"\n",
    "    def __init__(self, csv_file, data_root, split='train', \n",
    "                 transform=None, use_depth=False):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.data_root = Path(data_root)\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        self.use_depth = use_depth\n",
    "        \n",
    "        # 构建图像路径\n",
    "        self.rgb_dir = self.data_root / split / 'color'\n",
    "        if use_depth:\n",
    "            self.depth_dir = self.data_root / split / 'depth_raw'\n",
    "        \n",
    "        print(f\"加载 {split} 数据集: {len(self.df)} 个样本\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # 获取样本信息\n",
    "        row = self.df.iloc[idx]\n",
    "        dish_id = row['ID']\n",
    "        \n",
    "        # 加载RGB图像\n",
    "        rgb_path = self.rgb_dir / dish_id / 'rgb.png'\n",
    "        rgb = Image.open(rgb_path).convert('RGB')\n",
    "        \n",
    "        # 应用变换\n",
    "        if self.transform:\n",
    "            rgb = self.transform(rgb)\n",
    "        \n",
    "        # 准备返回值\n",
    "        sample = {\n",
    "            'image': rgb,\n",
    "            'dish_id': dish_id\n",
    "        }\n",
    "        \n",
    "        # 如果是训练集，添加标签\n",
    "        if 'Value' in row:\n",
    "            sample['calories'] = torch.tensor(row['Value'], dtype=torch.float32)\n",
    "        \n",
    "        # 如果使用深度图（baseline暂时不用）\n",
    "        if self.use_depth:\n",
    "            depth_path = self.depth_dir / dish_id / 'depth_raw.png'\n",
    "            depth = Image.open(depth_path)\n",
    "            depth = np.array(depth, dtype=np.float32) / 10000.0  # 转为米\n",
    "            depth = torch.from_numpy(depth).unsqueeze(0)  # (1, H, W)\n",
    "            sample['depth'] = depth\n",
    "        \n",
    "        return sample\n",
    "\n",
    "\n",
    "def get_transforms(split='train', image_size=224):\n",
    "    \"\"\"\n",
    "    获取数据变换\n",
    "    \n",
    "    Args:\n",
    "        split: 'train' 或 'val'/'test'\n",
    "        image_size: 目标图像尺寸\n",
    "    \"\"\"\n",
    "    if split == 'train':\n",
    "        # 训练集：数据增强\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((image_size, image_size)),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),  # 50%概率水平翻转\n",
    "            transforms.RandomRotation(degrees=15),    # ±15度旋转\n",
    "            transforms.ColorJitter(                   # 色彩抖动\n",
    "                brightness=0.2,\n",
    "                contrast=0.2,\n",
    "                saturation=0.2,\n",
    "                hue=0.1\n",
    "            ),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]\n",
    "            )\n",
    "        ])\n",
    "    else:\n",
    "        # 验证集/测试集：只做基本变换\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((image_size, image_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]\n",
    "            )\n",
    "        ])\n",
    "\n",
    "\n",
    "def create_dataloaders(data_root, train_csv, batch_size=32, \n",
    "                       val_split=0.2, num_workers=0, image_size=224):\n",
    "    \"\"\"\n",
    "    创建训练集和验证集的DataLoader\n",
    "    \n",
    "    Args:\n",
    "        data_root: 数据根目录\n",
    "        train_csv: 训练CSV文件路径\n",
    "        batch_size: 批次大小\n",
    "        val_split: 验证集比例（0.2 = 20%）\n",
    "        num_workers: 数据加载线程数\n",
    "        image_size: 图像尺寸\n",
    "    \n",
    "    Returns:\n",
    "        train_loader, val_loader\n",
    "    \"\"\"\n",
    "    # 读取完整训练集\n",
    "    full_df = pd.read_csv(train_csv)\n",
    "    \n",
    "    # 划分训练集和验证集\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train_df, val_df = train_test_split(\n",
    "        full_df, \n",
    "        test_size=val_split, \n",
    "        random_state=42,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    # 保存临时CSV\n",
    "    train_csv_path = Path(train_csv).parent / 'train_split.csv'\n",
    "    val_csv_path = Path(train_csv).parent / 'val_split.csv'\n",
    "    train_df.to_csv(train_csv_path, index=False)\n",
    "    val_df.to_csv(val_csv_path, index=False)\n",
    "    \n",
    "    print(f\"数据集划分: 训练={len(train_df)}, 验证={len(val_df)}\")\n",
    "    \n",
    "    # 创建数据集\n",
    "    train_dataset = Nutrition5kDataset(\n",
    "        csv_file=train_csv_path,\n",
    "        data_root=data_root,\n",
    "        split='train',\n",
    "        transform=get_transforms('train', image_size),\n",
    "        use_depth=False  # baseline不用深度图\n",
    "    )\n",
    "    \n",
    "    val_dataset = Nutrition5kDataset(\n",
    "        csv_file=val_csv_path,\n",
    "        data_root=data_root,\n",
    "        split='train',  # 注意：验证集也来自train目录\n",
    "        transform=get_transforms('val', image_size),\n",
    "        use_depth=False\n",
    "    )\n",
    "    \n",
    "    # 创建DataLoader\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True  # 加速GPU传输\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "# 测试代码\n",
    "if __name__ == '__main__':\n",
    "    # 测试数据加载\n",
    "    data_root = Path('Nutrition5K/Nutrition5K')\n",
    "    train_csv = data_root / 'nutrition5k_train.csv'\n",
    "    \n",
    "    train_loader, val_loader = create_dataloaders(\n",
    "        data_root=data_root,\n",
    "        train_csv=train_csv,\n",
    "        batch_size=16,\n",
    "        val_split=0.2\n",
    "    )\n",
    "    \n",
    "    # 获取一个batch查看\n",
    "    batch = next(iter(train_loader))\n",
    "    print(f\"\\nBatch信息:\")\n",
    "    print(f\"  图像shape: {batch['image'].shape}\")  # (B, 3, 224, 224)\n",
    "    print(f\"  卡路里shape: {batch['calories'].shape}\")  # (B,)\n",
    "    print(f\"  卡路里值: {batch['calories'][:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d210516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型参数量: 4,847,777\n",
      "\n",
      "输入shape: torch.Size([4, 3, 224, 224])\n",
      "输出shape: torch.Size([4, 1])\n",
      "输出值: tensor([0.0047, 0.0000, 0.0000, 0.0000], grad_fn=<SqueezeBackward0>)\n",
      "\n",
      "模型可训练: True\n",
      "第一层权重requires_grad: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BaselineCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Baseline CNN 用于卡路里预测\n",
    "    \n",
    "    架构：5个卷积块 + 2个全连接层\n",
    "    输入：(B, 3, 224, 224) RGB图像\n",
    "    输出：(B, 1) 卡路里预测值\n",
    "    \"\"\"\n",
    "    def __init__(self, dropout_rate=0.5):\n",
    "        super(BaselineCNN, self).__init__()\n",
    "        \n",
    "        # 卷积块 1: 3 -> 32\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2)  # 224 -> 112\n",
    "        )\n",
    "        \n",
    "        # 卷积块 2: 32 -> 64\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2)  # 112 -> 56\n",
    "        )\n",
    "        \n",
    "        # 卷积块 3: 64 -> 128\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2)  # 56 -> 28\n",
    "        )\n",
    "        \n",
    "        # 卷积块 4: 128 -> 256\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2)  # 28 -> 14\n",
    "        )\n",
    "        \n",
    "        # 卷积块 5: 256 -> 512\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2)  # 14 -> 7\n",
    "        )\n",
    "        \n",
    "        # 全局平均池化\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        # 全连接层\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(256, 1)  # 输出1个值\n",
    "        )\n",
    "        \n",
    "        # 权重初始化\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"使用He初始化\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "        \n",
    "        Args:\n",
    "            x: (B, 3, 224, 224) RGB图像\n",
    "        \n",
    "        Returns:\n",
    "            (B, 1) 卡路里预测值\n",
    "        \"\"\"\n",
    "        x = self.conv1(x)   # (B, 32, 112, 112)\n",
    "        x = self.conv2(x)   # (B, 64, 56, 56)\n",
    "        x = self.conv3(x)   # (B, 128, 28, 28)\n",
    "        x = self.conv4(x)   # (B, 256, 14, 14)\n",
    "        x = self.conv5(x)   # (B, 512, 7, 7)\n",
    "        \n",
    "        # 全局平均池化\n",
    "        x = self.global_avg_pool(x)  # (B, 512, 1, 1)\n",
    "        x = x.view(x.size(0), -1)     # (B, 512)\n",
    "        \n",
    "        # 全连接层\n",
    "        x = self.fc(x)  # (B, 1)\n",
    "        \n",
    "        # 确保输出非负（卡路里不能为负）\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    \"\"\"计算模型参数量\"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "# 测试代码\n",
    "if __name__ == '__main__':\n",
    "    # 创建模型\n",
    "    model = BaselineCNN(dropout_rate=0.5)\n",
    "    \n",
    "    # 统计参数\n",
    "    num_params = count_parameters(model)\n",
    "    print(f\"模型参数量: {num_params:,}\")\n",
    "    \n",
    "    # 测试前向传播\n",
    "    batch_size = 4\n",
    "    dummy_input = torch.randn(batch_size, 3, 224, 224)\n",
    "    \n",
    "    print(f\"\\n输入shape: {dummy_input.shape}\")\n",
    "    \n",
    "    # 前向传播\n",
    "    output = model(dummy_input)\n",
    "    print(f\"输出shape: {output.shape}\")\n",
    "    print(f\"输出值: {output.squeeze()}\")\n",
    "    \n",
    "    # 检查梯度流\n",
    "    print(f\"\\n模型可训练: {model.training}\")\n",
    "    print(f\"第一层权重requires_grad: {model.conv1[0].weight.requires_grad}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvass2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
