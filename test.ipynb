{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b08196c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "def analyze_outliers(csv_path):\n",
    "    \"\"\"分析卡路里数据的异常值\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    calories = df['Value']\n",
    "    \n",
    "    # 基本统计\n",
    "    print(\"=\" * 60)\n",
    "    print(\"卡路里数据统计:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(calories.describe())\n",
    "    print(f\"\\n中位数: {calories.median():.2f}\")\n",
    "    print(f\"偏度: {calories.skew():.2f}\")  # 正偏说明右偏\n",
    "    \n",
    "    # 检测异常值\n",
    "    mean = calories.mean()\n",
    "    std = calories.std()\n",
    "    \n",
    "    # 3-sigma规则\n",
    "    lower_bound = mean - 3 * std\n",
    "    upper_bound = mean + 3 * std\n",
    "    outliers_3sigma = df[(calories < lower_bound) | (calories > upper_bound)]\n",
    "    \n",
    "    # IQR方法（更稳健）\n",
    "    q1 = calories.quantile(0.25)\n",
    "    q3 = calories.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_iqr = q1 - 1.5 * iqr\n",
    "    upper_iqr = q3 + 1.5 * iqr\n",
    "    outliers_iqr = df[(calories < lower_iqr) | (calories > upper_iqr)]\n",
    "    \n",
    "    print(f\"\\n3-sigma范围: [{lower_bound:.2f}, {upper_bound:.2f}]\")\n",
    "    print(f\"3-sigma异常值数量: {len(outliers_3sigma)} ({len(outliers_3sigma)/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nIQR范围: [{lower_iqr:.2f}, {upper_iqr:.2f}]\")\n",
    "    print(f\"IQR异常值数量: {len(outliers_iqr)} ({len(outliers_iqr)/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    # 可视化\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    \n",
    "    # 直方图\n",
    "    axes[0].hist(calories, bins=50, edgecolor='black')\n",
    "    axes[0].axvline(mean, color='r', linestyle='--', label=f'Mean: {mean:.0f}')\n",
    "    axes[0].axvline(mean + 3*std, color='orange', linestyle='--', label='3σ')\n",
    "    axes[0].axvline(mean - 3*std, color='orange', linestyle='--')\n",
    "    axes[0].set_xlabel('Calories')\n",
    "    axes[0].set_ylabel('Frequency')\n",
    "    axes[0].set_title('Distribution')\n",
    "    axes[0].legend()\n",
    "    \n",
    "    # 箱线图\n",
    "    axes[1].boxplot(calories)\n",
    "    axes[1].set_ylabel('Calories')\n",
    "    axes[1].set_title('Box Plot')\n",
    "    axes[1].grid(alpha=0.3)\n",
    "    \n",
    "    # Q-Q图（检查正态性）\n",
    "    from scipy import stats\n",
    "    stats.probplot(calories, dist=\"norm\", plot=axes[2])\n",
    "    axes[2].set_title('Q-Q Plot')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('data_analysis.png', dpi=150)\n",
    "    print(\"\\n可视化已保存到 data_analysis.png\")\n",
    "    \n",
    "    return outliers_3sigma, outliers_iqr\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    DATA_ROOT = Path('Nutrition5K/Nutrition5K')\n",
    "    TRAIN_CSV = DATA_ROOT / 'nutrition5k_train_clean.csv'\n",
    "    \n",
    "    outliers_3sigma, outliers_iqr = analyze_outliers(TRAIN_CSV)\n",
    "    \n",
    "    print(\"\\n最高的10个卡路里值:\")\n",
    "    df = pd.read_csv(TRAIN_CSV)\n",
    "    print(df.nlargest(10, 'Value')[['ID', 'Value']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91930752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    3300.000000\n",
      "mean      237.298713\n",
      "std       221.319200\n",
      "min         0.000000\n",
      "25%        60.839996\n",
      "50%       186.821724\n",
      "75%       359.282753\n",
      "max      3943.325195\n",
      "Name: Value, dtype: float64\n",
      "前5个值: [221.167068, 140.980011, 274.335999, 589.501648, 258.59967]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Nutrition5K/Nutrition5K/nutrition5k_train_clean.csv')\n",
    "print(df['Value'].describe())\n",
    "print('前5个值:', df['Value'].head().tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3210992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "扫描 3300 张深度图...\n",
      "采样间隔: 每 2027 个像素采样1个\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3300/3300 [00:28<00:00, 113.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "扫描完成: 3300 成功, 0 失败\n",
      "总像素数: 842,661,995\n",
      "\n",
      "============================================================\n",
      "深度统计 (16-bit原始值):\n",
      "============================================================\n",
      "  min: 323.00\n",
      "  max: 65535.00\n",
      "  mean: 3754.93\n",
      "  std: 861.26\n",
      "  median: 3588.00\n",
      "  p95: 4118.00\n",
      "  p99: 4286.00\n",
      "  total_pixels: 842,661,995\n",
      "  valid_images: 3,300\n",
      "  failed_images: 0\n",
      "\n",
      "假设单位: 0.1mm (scale=1e-4米)\n",
      "  99th百分位: 0.429 米\n",
      "  推荐归一化参数: depth_max_value = 4286\n",
      "\n",
      "结果已保存: Nutrition5K\\Nutrition5K\\depth_statistics.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# analyze_depth_range.py (最终版 - 内存安全)\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "def analyze_depth_distribution(data_root):\n",
    "    \"\"\"使用在线统计，避免内存爆炸\"\"\"\n",
    "    data_root = Path(data_root)\n",
    "    train_csv = pd.read_csv(data_root / 'nutrition5k_train_clean.csv')\n",
    "    \n",
    "    # 在线统计量\n",
    "    pixel_count = 0\n",
    "    sum_values = 0.0\n",
    "    sum_squares = 0.0\n",
    "    min_value = float('inf')\n",
    "    max_value = 0.0\n",
    "    \n",
    "    # 采样用于百分位（内存限制）\n",
    "    max_samples = 500_000  # 最多50万个采样点\n",
    "    sample_interval = max(1, len(train_csv) * 307200 // max_samples)  # 动态采样率\n",
    "    percentile_samples = []\n",
    "    \n",
    "    print(f\"扫描 {len(train_csv)} 张深度图...\")\n",
    "    print(f\"采样间隔: 每 {sample_interval} 个像素采样1个\")\n",
    "    \n",
    "    valid_count = 0\n",
    "    failed_count = 0\n",
    "    \n",
    "    for idx, row in tqdm(train_csv.iterrows(), total=len(train_csv)):\n",
    "        dish_id = row['ID']\n",
    "        depth_path = data_root / 'train' / 'depth_raw' / dish_id / 'depth_raw.png'\n",
    "        \n",
    "        if not depth_path.exists():\n",
    "            failed_count += 1\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            depth_img = Image.open(depth_path)\n",
    "            depth_array = np.array(depth_img, dtype=np.uint16)\n",
    "            valid_depth = depth_array[depth_array > 0]\n",
    "            \n",
    "            if len(valid_depth) == 0:\n",
    "                continue\n",
    "            \n",
    "            # 在线更新统计\n",
    "            pixel_count += len(valid_depth)\n",
    "            sum_values += valid_depth.sum()\n",
    "            sum_squares += (valid_depth.astype(np.float64) ** 2).sum()\n",
    "            min_value = min(min_value, valid_depth.min())\n",
    "            max_value = max(max_value, valid_depth.max())\n",
    "            \n",
    "            # 采样（防止内存爆炸）\n",
    "            if len(percentile_samples) < max_samples:\n",
    "                sample_size = max(1, len(valid_depth) // sample_interval)\n",
    "                indices = np.random.choice(len(valid_depth), size=min(sample_size, len(valid_depth)), replace=False)\n",
    "                percentile_samples.extend(valid_depth[indices].tolist())\n",
    "            \n",
    "            valid_count += 1\n",
    "            \n",
    "        except MemoryError:\n",
    "            print(f\"\\n内存错误在 {dish_id}，当前已处理 {valid_count} 张\")\n",
    "            failed_count += 1\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            failed_count += 1\n",
    "            if failed_count <= 5:\n",
    "                print(f\"\\n错误 {dish_id}: {type(e).__name__}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\n扫描完成: {valid_count} 成功, {failed_count} 失败\")\n",
    "    print(f\"总像素数: {pixel_count:,}\")\n",
    "    \n",
    "    if pixel_count == 0:\n",
    "        print(\"错误：没有有效数据\")\n",
    "        return None\n",
    "    \n",
    "    # 计算统计量\n",
    "    mean = sum_values / pixel_count\n",
    "    variance = (sum_squares / pixel_count) - (mean ** 2)\n",
    "    std = np.sqrt(max(0, variance))\n",
    "    \n",
    "    # 百分位\n",
    "    percentile_samples = np.array(percentile_samples)\n",
    "    median = np.median(percentile_samples)\n",
    "    p95 = np.percentile(percentile_samples, 95)\n",
    "    p99 = np.percentile(percentile_samples, 99)\n",
    "    \n",
    "    stats = {\n",
    "        'min': float(min_value),\n",
    "        'max': float(max_value),\n",
    "        'mean': float(mean),\n",
    "        'std': float(std),\n",
    "        'median': float(median),\n",
    "        'p95': float(p95),\n",
    "        'p99': float(p99),\n",
    "        'total_pixels': int(pixel_count),\n",
    "        'valid_images': int(valid_count),\n",
    "        'failed_images': int(failed_count)\n",
    "    }\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"深度统计 (16-bit原始值):\")\n",
    "    print(\"=\"*60)\n",
    "    for key, val in stats.items():\n",
    "        if 'pixels' in key or 'images' in key:\n",
    "            print(f\"  {key}: {val:,}\")\n",
    "        else:\n",
    "            print(f\"  {key}: {val:.2f}\")\n",
    "    \n",
    "    print(\"\\n假设单位: 0.1mm (scale=1e-4米)\")\n",
    "    print(f\"  99th百分位: {p99 * 1e-4:.3f} 米\")\n",
    "    print(f\"  推荐归一化参数: depth_max_value = {int(p99)}\")\n",
    "    \n",
    "    # 保存\n",
    "    import json\n",
    "    with open(data_root / 'depth_statistics.json', 'w') as f:\n",
    "        json.dump(stats, f, indent=2)\n",
    "    \n",
    "    print(f\"\\n结果已保存: {data_root / 'depth_statistics.json'}\")\n",
    "    \n",
    "    return stats\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    stats = analyze_depth_distribution('Nutrition5K/Nutrition5K')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvass2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
